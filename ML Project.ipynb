{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2968e715-baa7-43bb-9fed-91e08151516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data handling\n",
    "#!pip install --upgrade scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#feature selection\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "#classification\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# performance metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import balanced_accuracy_score,f1_score,precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee006e-9a9d-4a17-ba60-2abe5c60e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data directly from a github repository\n",
    "\n",
    "file_url='https://github.com/aryac-08/ML-Project1/raw/main/cancer_gene_expression%20(1).zip'\n",
    "\n",
    "dataframe=pd.read_csv(file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31734ecd-24f4-4bfc-806a-36c58fdb6ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's check the number of samples and features\n",
    "#note:the last column contain the labels. it is not considered as a feature\n",
    "\n",
    "print(dataframe.shape)\n",
    "#let's check some of the columns (first, second and third columns)\n",
    "print(dataframe.columns[0:3])\n",
    "#lets check the name of the last column of this dataframe\n",
    "\n",
    "dataframe.columns[-1]\n",
    "#check for missing values\n",
    "datanul=dataframe.isnull().sum()\n",
    "g=[i for i in datanul if i>0]\n",
    "\n",
    "print('columns with missing values:%d'%len(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8c1c1b-a8d4-4b3d-a34c-674eb15096be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's check how many different cancer types are there in the data\n",
    "#note: in this tutorial the cancer types will be referred to as classes or labels\n",
    "\n",
    "print(dataframe['Cancer_Type'].value_counts())\n",
    "\n",
    "#plot a bar chat to display the class distribution\n",
    "\n",
    "dataframe['Cancer_Type'].value_counts().plot.bar()\n",
    "\n",
    "#we will now seperate the feature values from the class. we do this because scikit-learn requires that features and class are separated before parsing them to the classifiers.\n",
    "\n",
    "X=dataframe.iloc[:,0:-1]\n",
    "y=dataframe.iloc[:,-1]\n",
    "\n",
    "X.shape\n",
    "y.shape\n",
    "#let's encode target labels (y) with values between 0 and n_classes-1.\n",
    "#encoding will be done using the LabelEncoder\n",
    "label_encoder=LabelEncoder()\n",
    "label_encoder.fit(y)\n",
    "y_encoded=label_encoder.transform(y)\n",
    "labels=label_encoder.classes_\n",
    "classes=np.unique(y_encoded)\n",
    "labels\n",
    "classes\n",
    "#split data into training and test sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y_encoded,test_size=0.2,random_state=42)\n",
    "dataframe.iloc[:,0:10].describe()\n",
    "# scale data between 0 and 1\n",
    "\n",
    "min_max_scaler=MinMaxScaler()\n",
    "X_train_norm=min_max_scaler.fit_transform(X_train)\n",
    "X_test_norm=min_max_scaler.fit_transform(X_test)\n",
    "\n",
    "MI=mutual_info_classif(X_train_norm,y_train)\n",
    "#select top n features. lets say 300.\n",
    "#you can modify the value and see how the performance of the model changes\n",
    "\n",
    "n_features=300\n",
    "selected_scores_indices=np.argsort(MI)[::-1][0:n_features]\n",
    "X_train_selected=X_train_norm[:,selected_scores_indices]\n",
    "X_test_selected=X_test_norm[:,selected_scores_indices]\n",
    "X_train_selected.shape\n",
    "X_test_selected.shape\n",
    "#Random Forest Classifier\n",
    "#because we are dealing with multiclass data, the one versus rest strategy is used.\n",
    "#learn to predict each class against the other.\n",
    "\n",
    "RF=OneVsRestClassifier(RandomForestClassifier(max_features=0.2))\n",
    "RF.fit(X_train_selected,y_train)\n",
    "y_pred =RF.predict(X_test_selected)\n",
    "pred_prob = RF.predict_proba(X_test_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee528ee-c967-4e1b-a9de-bb19870c47ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy\n",
    "accuracy=np.round(balanced_accuracy_score(y_test,y_pred),4)\n",
    "print('accuracy:%0.4f'%accuracy)\n",
    "\n",
    "#precision\n",
    "precision=np.round(precision_score(y_test,y_pred,average = 'weighted'),4)\n",
    "print('precision:%0.4f'%precision)\n",
    "\n",
    "#recall\n",
    "recall=np.round(recall_score(y_test,y_pred,average = 'weighted'),4)\n",
    "print('recall:%0.4f'%recall)\n",
    "\n",
    "#f1score\n",
    "f1score=np.round(f1_score(y_test,y_pred,average = 'weighted'),4)\n",
    "print('f1score:%0.4f'%f1score)\n",
    "\n",
    "\n",
    "report=classification_report(y_test,y_pred, target_names=labels)\n",
    "print('\\n')\n",
    "print('classification report\\n\\n')\n",
    "print(report)\n",
    "\n",
    "#generate confusion matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "cm_df=pd.DataFrame(cm,index=labels,columns=labels)\n",
    "cm_df\n",
    "#visualize the confusion matrix using seaborn\n",
    "\n",
    "sns.heatmap(cm_df,annot=True,cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "#visualize the confusion matrix directly\n",
    "#disp=plot_confusion_matrix(RF,X_test_selected,y_test,xticks_rotation='vertical',\n",
    "                     #cmap='Blues',display_labels=labels)\n",
    "#roc curves will be generated for each class\n",
    "#we will therefore have to binarize the y_test labels\n",
    "#this is done because the probabilities(pred_prob) are calculated for each each class\n",
    "#we therefore need to put the y_test label in the same format as the pred_prob\n",
    "y_test_binarized=label_binarize(y_test,classes=classes)\n",
    "\n",
    "# roc curve for classes\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "thresh ={}\n",
    "roc_auc = dict()\n",
    "\n",
    "n_class = classes.shape[0]\n",
    "\n",
    "for i in range(n_class):    \n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(y_test_binarized[:,i], pred_prob[:,i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # plotting    \n",
    "    plt.plot(fpr[i], tpr[i], linestyle='--', \n",
    "             label='%s vs Rest (AUC=%0.2f)'%(labels[i],roc_auc[i]))\n",
    "\n",
    "plt.plot([0,1],[0,1],'b--')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1.05])\n",
    "plt.title('Multiclass ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
